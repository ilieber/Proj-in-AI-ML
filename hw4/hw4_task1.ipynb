{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Projects in AI and ML HW4 Task 1\n",
        "\n",
        "For this task, I used the character level RNN from https://github.com/karpathy/char-rnn. However, as this is a legacy repository and has the code written in a different language (not python), I found a more recent version of it here: https://github.com/olivatooo/char-rnn.pytorch.\n",
        "I used the 'tiny Shakespeare' dataset from the first repository and trained it on the RNN model for 5, 50 and 500 epochs. I did this again using the LSTM model as well."
      ],
      "metadata": {
        "id": "-w7-2nXZa7iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/olivatooo/char-rnn.pytorch.git\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQhcsspZ7tRP",
        "outputId": "83b091cc-10f9-4876-e830-2b0c3cc7a6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'char-rnn.pytorch'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Total 61 (delta 0), reused 0 (delta 0), pack-reused 61 (from 1)\u001b[K\n",
            "Receiving objects: 100% (61/61), 13.66 KiB | 537.00 KiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "--2025-02-25 21:20:05--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-02-25 21:20:05 (16.5 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "!python char-rnn.pytorch/train.py input.txt --n_epochs 5\n",
        "!python char-rnn.pytorch/generate.py input.pt --prime_str \"Where\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa2x6FlV8i4q",
        "outputId": "34b481ad-6317-403a-ef4d-4fc88965bae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.11/dist-packages (1.3.8)\n",
            "Training for 5 epochs...\n",
            "100% 5/5 [00:03<00:00,  1.57it/s]\n",
            "Saving...\n",
            "Saved as input.pt\n",
            "/content/char-rnn/char-rnn.pytorch/generate.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  decoder = torch.load(args.filename)\n",
            "Whereue ,\n",
            "iS  Ie ne omaa nooe\n",
            "d, dtd a impathna koiiaae\n",
            " iau dt\n",
            "tne eee\n",
            " ssrouteaese aoeda eo teo and aif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python char-rnn.pytorch/train.py input.txt --n_epochs 50\n",
        "!python char-rnn.pytorch/generate.py input.pt --prime_str \"Where\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhVMmcPr_dCx",
        "outputId": "62298353-0701-415c-b068-1d391ca92a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 50 epochs...\n",
            "100% 50/50 [00:31<00:00,  1.60it/s]\n",
            "Saving...\n",
            "Saved as input.pt\n",
            "/content/char-rnn/char-rnn.pytorch/generate.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  decoder = torch.load(args.filename)\n",
            "Where hispest well to have that bosou's like a my wlard sout the buse\n",
            "And lemave for of lieng I king my t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python char-rnn.pytorch/train.py input.txt --n_epochs 500\n",
        "!python char-rnn.pytorch/generate.py input.pt --prime_str \"Where\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm7fO2wz_eCm",
        "outputId": "44f8023a-3fff-41d8-8325-dd2e4d6d7b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 500 epochs...\n",
            " 20% 99/500 [01:01<04:35,  1.45it/s][1m 2s (100 20%) 1.7652]\n",
            "Where,\n",
            "I mundessed, thy lord, own of thou depokes,-serack am; and far\n",
            "Thou traith have fortor:---on th \n",
            "\n",
            " 40% 199/500 [02:03<02:58,  1.69it/s][2m 3s (200 40%) 1.6010]\n",
            "Where in a shall good const,\n",
            "I'll both time upon fillio fear thy gacrose; if you,\n",
            "And I preturn'd be o \n",
            "\n",
            " 60% 299/500 [03:05<02:00,  1.67it/s][3m 5s (300 60%) 1.5282]\n",
            "What will she hears for:\n",
            "The ragings but I tell tain and grous be trown lord with a stands\n",
            "Stands shes \n",
            "\n",
            " 80% 399/500 [04:07<01:03,  1.58it/s][4m 7s (400 80%) 1.4688]\n",
            "What do the parting a cackel.\n",
            "\n",
            "LEONTES:\n",
            "Mows' deserver, his enough you\n",
            "My heart most failtion of Prani \n",
            "\n",
            "100% 499/500 [05:10<00:00,  1.65it/s][5m 10s (500 100%) 1.4873]\n",
            "Where he says to liberted;\n",
            "And I know thy innogestion; the warter larged,\n",
            "More than the time have lell \n",
            "\n",
            "100% 500/500 [05:10<00:00,  1.61it/s]\n",
            "Saving...\n",
            "Saved as input.pt\n",
            "/content/char-rnn/char-rnn.pytorch/generate.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  decoder = torch.load(args.filename)\n",
            "Where what he would not stay shows him day,\n",
            "To you will is heaven his rest be his scield.\n",
            "\n",
            "PAULINA:\n",
            "Are a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python char-rnn.pytorch/train.py input.txt --model LSTM --n_epochs 5\n",
        "!python char-rnn.pytorch/generate.py input.pt --prime_str \"Where\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RonPVNhY_gts",
        "outputId": "e9c2272a-d7b6-4725-d257-b24ec8002bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 5 epochs...\n",
            "100% 5/5 [00:05<00:00,  1.18s/it]\n",
            "Saving...\n",
            "Saved as input.pt\n",
            "/content/char-rnn/char-rnn.pytorch/generate.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  decoder = torch.load(args.filename)\n",
            "Where e  hon  l aen s lah  nne  e   r tnaa u eto  a n T:a o   ier oe r r\n",
            "irhhernnra ar dl e\n",
            "txad o to ih \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python char-rnn.pytorch/train.py input.txt --model LSTM --n_epochs 50\n",
        "!python char-rnn.pytorch/generate.py input.pt --prime_str \"Where\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWiqxhRg_t_3",
        "outputId": "13915455-200a-407d-c728-04bd51c9e1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 50 epochs...\n",
            "100% 50/50 [00:43<00:00,  1.16it/s]\n",
            "Saving...\n",
            "Saved as input.pt\n",
            "/content/char-rnn/char-rnn.pytorch/generate.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  decoder = torch.load(args.filename)\n",
            "Where hasans norg thous the sire he sor ert hey fond hous he sirram:\n",
            "Honth noes-then kmice thasnt for anl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python char-rnn.pytorch/train.py input.txt --model LSTM --n_epochs 500\n",
        "!python char-rnn.pytorch/generate.py input.pt --prime_str \"Where\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZekHxNEK_u7w",
        "outputId": "ee505d60-96f3-4ba0-bbe0-ca2e7412bccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 500 epochs...\n",
            " 20% 99/500 [01:21<05:07,  1.30it/s][1m 22s (100 20%) 1.9382]\n",
            "Whind ut a more thait for of do how gleagheld this not hings from my I gell to have you wate.\n",
            "\n",
            "LIHA VI \n",
            "\n",
            " 40% 199/500 [02:43<04:29,  1.12it/s][2m 44s (200 40%) 1.6897]\n",
            "Whill love fakeals, cheets, whose wo the word in your the pases? and her the conshore,\n",
            "My lord, and li \n",
            "\n",
            " 60% 299/500 [04:03<02:58,  1.12it/s][4m 4s (300 60%) 1.6009]\n",
            "What stand to hordeed and to peagain, in the kind croad,\n",
            "But tay, tongue will not or did to my love th \n",
            "\n",
            " 80% 399/500 [05:24<01:27,  1.15it/s][5m 25s (400 80%) 1.5434]\n",
            "What time,\n",
            "He this stroy to this' words Marcal'd.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Why why the permanius to a deeds, t \n",
            "\n",
            "100% 499/500 [06:45<00:00,  1.22it/s][6m 45s (500 100%) 1.5101]\n",
            "Where how at is dost revarth, not frown? or shall be retore.\n",
            "\n",
            "Clown:\n",
            "Since of the kindles of stroke me \n",
            "\n",
            "100% 500/500 [06:45<00:00,  1.23it/s]\n",
            "Saving...\n",
            "Saved as input.pt\n",
            "/content/char-rnn/char-rnn.pytorch/generate.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  decoder = torch.load(args.filename)\n",
            "Wherefore our may stay to your come with Lucentio, by grief,\n",
            "Or Houble thee.\n",
            "\n",
            "SAMPSON:\n",
            "Therefore man for \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a fairly significant difference between the outputs from the three different epochs. The output for 5 epochs is practically gibberish and doesn't really make sense at all. The output for 50 epochs is better than 5 but still not really comprehensable English. 500 epochs is much better (although still not perfect). This is because using more epochs allows the model to learn more from the data, resulting in a better output.  \n",
        "\n",
        "  \n",
        "I don't notice much difference between the first model and the LSTM model. They both have similar results in regards to becoming more accurate as more epochs are used. Both models still output mostly gibberish, but it is somewhat minimally comprehensible, especially since Shakespeare language itself is not always very clear."
      ],
      "metadata": {
        "id": "aQ8qEWxLAMIM"
      }
    }
  ]
}